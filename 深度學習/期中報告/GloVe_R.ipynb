{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.data_utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Dense, Flatten, LSTM, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 選擇數據處理模式：'N-R' 或 'R'\n",
    "mode = 'R'  # 可以選擇 'N-R' 或 'R'\n",
    "\n",
    "# 載入與預處理數據\n",
    "def load_semeval_data(file_paths):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) == 3:\n",
    "                    data.append(parts[2])\n",
    "                    labels.append(parts[1])\n",
    "    return pd.DataFrame({'tweet': data, 'label': labels})\n",
    "\n",
    "file_paths = [\n",
    "    './dataset/train/twitter-2013train-A.txt',\n",
    "    './dataset/train/twitter-2014test-A.txt',\n",
    "    './dataset/train/twitter-2015train-A.txt'\n",
    "]\n",
    "\n",
    "dataset = load_semeval_data(file_paths)\n",
    "\n",
    "# 預處理推文文本\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"https?:\\/\\/\\S+\", \"\", tweet)\n",
    "    tweet = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", tweet)\n",
    "    return tweet\n",
    "\n",
    "dataset['tweet'] = dataset['tweet'].apply(preprocess_tweet)\n",
    "\n",
    "# Tokenization 和 Padding 設置\n",
    "MAX_NB_WORDS = 10000\n",
    "MAX_SEQUENCE_LENGTH = 40  # 用於 N-R 模式\n",
    "REGION_SIZE = 10  # 每個區域的長度，用於 R 模式\n",
    "NUM_REGIONS = 4  # 區域數量，用於 R 模式\n",
    "EMBEDDING_DIM = 25\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(dataset['tweet'].values)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# 根據模式選擇不同的數據處理方法\n",
    "if mode == 'N-R':\n",
    "    # Non-Regional 模式，直接將推文轉為固定長度序列\n",
    "    X = tokenizer.texts_to_sequences(dataset['tweet'].values)\n",
    "    X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    input_length = MAX_SEQUENCE_LENGTH  # 設置模型的 input_length\n",
    "elif mode == 'R':\n",
    "    # Regional 模式，將推文分成多個區域並填充至相同長度\n",
    "    X = tokenizer.texts_to_sequences(dataset['tweet'].values)\n",
    "    X_padded = []\n",
    "    for tweet in X:\n",
    "        tweet_regions = []\n",
    "        for i in range(NUM_REGIONS):\n",
    "            start = i * REGION_SIZE\n",
    "            end = start + REGION_SIZE\n",
    "            region = tweet[start:end]\n",
    "            if len(region) < REGION_SIZE:\n",
    "                region = region + [0] * (REGION_SIZE - len(region))\n",
    "            tweet_regions.extend(region)\n",
    "        X_padded.append(tweet_regions)\n",
    "    X = np.array(X_padded)\n",
    "    input_length = NUM_REGIONS * REGION_SIZE  # 設置模型的 input_length\n",
    "else:\n",
    "    raise ValueError(\"Invalid mode. Choose 'N-R' or 'R'.\")\n",
    "\n",
    "# 標籤處理\n",
    "label_mapping = {'positive': 0, 'negative': 1, 'neutral': 2}\n",
    "y = dataset['label'].map(label_mapping).values\n",
    "y = pd.get_dummies(y).values\n",
    "\n",
    "# 數據分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 載入 GloVe 詞嵌入\n",
    "embeddings_index = {}\n",
    "with open(r'C:\\Users\\jk121\\Documents\\Code\\LargeData\\glove.twitter.27B.25d.txt', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# 定義嵌入層，用於後續模型\n",
    "embedding_layer = Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                            input_length=input_length, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "301/301 [==============================] - 2s 4ms/step - loss: 0.9992 - accuracy: 0.4906 - val_loss: 0.9486 - val_accuracy: 0.5208\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 1s 3ms/step - loss: 0.9100 - accuracy: 0.5553 - val_loss: 0.9060 - val_accuracy: 0.5532\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 1s 3ms/step - loss: 0.8595 - accuracy: 0.5874 - val_loss: 0.8632 - val_accuracy: 0.5873\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 1s 3ms/step - loss: 0.8305 - accuracy: 0.6086 - val_loss: 0.8500 - val_accuracy: 0.5981\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 1s 3ms/step - loss: 0.8145 - accuracy: 0.6199 - val_loss: 0.8424 - val_accuracy: 0.5977\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 1s 3ms/step - loss: 0.7986 - accuracy: 0.6296 - val_loss: 0.8369 - val_accuracy: 0.6035\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 1s 2ms/step - loss: 0.7857 - accuracy: 0.6387 - val_loss: 0.8348 - val_accuracy: 0.6039\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 1s 3ms/step - loss: 0.7761 - accuracy: 0.6463 - val_loss: 0.8370 - val_accuracy: 0.6031\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 1s 2ms/step - loss: 0.7672 - accuracy: 0.6504 - val_loss: 0.8254 - val_accuracy: 0.6147\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 1s 3ms/step - loss: 0.7594 - accuracy: 0.6591 - val_loss: 0.8225 - val_accuracy: 0.6172\n",
      "76/76 [==============================] - 0s 753us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.60      0.62       921\n",
      "           1       0.45      0.26      0.33       341\n",
      "           2       0.63      0.74      0.68      1144\n",
      "\n",
      "    accuracy                           0.62      2406\n",
      "   macro avg       0.57      0.53      0.54      2406\n",
      "weighted avg       0.61      0.62      0.61      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten\n",
    "\n",
    "# 建立單一 CNN 模型並加入 Flatten 層\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                        input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "cnn_model.add(Conv1D(filters=12, kernel_size=3, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=3))\n",
    "cnn_model.add(Flatten())  # 加入 Flatten 層\n",
    "cnn_model.add(Dense(3, activation='softmax'))\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = cnn_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "301/301 [==============================] - 19s 58ms/step - loss: 0.9542 - accuracy: 0.5062 - val_loss: 0.8791 - val_accuracy: 0.6022\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 17s 57ms/step - loss: 0.8882 - accuracy: 0.5787 - val_loss: 0.8952 - val_accuracy: 0.5910\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 17s 57ms/step - loss: 0.8589 - accuracy: 0.5944 - val_loss: 0.8201 - val_accuracy: 0.6247\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 17s 56ms/step - loss: 0.8405 - accuracy: 0.6111 - val_loss: 0.8119 - val_accuracy: 0.6205\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 17s 57ms/step - loss: 0.8306 - accuracy: 0.6085 - val_loss: 0.8289 - val_accuracy: 0.6085\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 17s 57ms/step - loss: 0.8158 - accuracy: 0.6229 - val_loss: 0.8075 - val_accuracy: 0.6500\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 18s 60ms/step - loss: 0.8061 - accuracy: 0.6294 - val_loss: 0.7809 - val_accuracy: 0.6397\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 18s 61ms/step - loss: 0.7856 - accuracy: 0.6433 - val_loss: 0.7758 - val_accuracy: 0.6451\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 19s 62ms/step - loss: 0.7846 - accuracy: 0.6442 - val_loss: 0.7732 - val_accuracy: 0.6625\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 19s 62ms/step - loss: 0.7760 - accuracy: 0.6543 - val_loss: 0.7836 - val_accuracy: 0.6617\n",
      "76/76 [==============================] - 1s 14ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.54      0.63       921\n",
      "           1       0.53      0.23      0.33       341\n",
      "           2       0.63      0.89      0.74      1144\n",
      "\n",
      "    accuracy                           0.66      2406\n",
      "   macro avg       0.64      0.55      0.57      2406\n",
      "weighted avg       0.67      0.66      0.64      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 單一 LSTM 模型 (Single LSTM)\n",
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# 建立單一 LSTM 模型\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                         input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm_model.add(Dense(3, activation='softmax'))\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = lstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "301/301 [==============================] - 9s 23ms/step - loss: 0.9796 - accuracy: 0.5012 - val_loss: 0.9059 - val_accuracy: 0.5619\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 6s 22ms/step - loss: 0.8982 - accuracy: 0.5674 - val_loss: 0.8681 - val_accuracy: 0.5964\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 7s 22ms/step - loss: 0.8613 - accuracy: 0.5915 - val_loss: 0.8311 - val_accuracy: 0.6122\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 6s 21ms/step - loss: 0.8384 - accuracy: 0.6042 - val_loss: 0.8194 - val_accuracy: 0.6234\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 6s 21ms/step - loss: 0.8222 - accuracy: 0.6221 - val_loss: 0.8112 - val_accuracy: 0.6272\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 6s 20ms/step - loss: 0.8085 - accuracy: 0.6271 - val_loss: 0.8101 - val_accuracy: 0.6164\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 6s 20ms/step - loss: 0.8004 - accuracy: 0.6308 - val_loss: 0.7914 - val_accuracy: 0.6301\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 6s 20ms/step - loss: 0.7929 - accuracy: 0.6334 - val_loss: 0.7829 - val_accuracy: 0.6334\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 6s 20ms/step - loss: 0.7795 - accuracy: 0.6462 - val_loss: 0.7840 - val_accuracy: 0.6326\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 6s 20ms/step - loss: 0.7747 - accuracy: 0.6488 - val_loss: 0.7839 - val_accuracy: 0.6417\n",
      "76/76 [==============================] - 1s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.65       921\n",
      "           1       0.46      0.26      0.33       341\n",
      "           2       0.64      0.77      0.70      1144\n",
      "\n",
      "    accuracy                           0.64      2406\n",
      "   macro avg       0.60      0.55      0.56      2406\n",
      "weighted avg       0.63      0.64      0.63      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CNN + LSTM 組合模型 (CNN + LSTM Combined Network)\n",
    "\n",
    "# 建立 CNN + LSTM 模型\n",
    "cnn_lstm_model = Sequential()\n",
    "cnn_lstm_model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                             input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "cnn_lstm_model.add(Conv1D(filters=12, kernel_size=3, activation='relu'))\n",
    "cnn_lstm_model.add(MaxPooling1D(pool_size=3))\n",
    "cnn_lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "cnn_lstm_model.add(Dense(3, activation='softmax'))\n",
    "cnn_lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "cnn_lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = cnn_lstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 785us/step\n",
      "301/301 [==============================] - 4s 13ms/step\n",
      "76/76 [==============================] - 0s 781us/step\n",
      "76/76 [==============================] - 1s 12ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.53      0.51       921\n",
      "           1       0.00      0.00      0.00       341\n",
      "           2       0.56      0.70      0.62      1144\n",
      "\n",
      "    accuracy                           0.54      2406\n",
      "   macro avg       0.35      0.41      0.38      2406\n",
      "weighted avg       0.46      0.54      0.49      2406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# CNN 特徵提取模型\n",
    "cnn_feature_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    Conv1D(filters=12, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    Flatten()\n",
    "])\n",
    "\n",
    "# LSTM 特徵提取模型\n",
    "lstm_feature_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Flatten()\n",
    "])\n",
    "\n",
    "# 提取 CNN 和 LSTM 特徵\n",
    "cnn_features = cnn_feature_model.predict(X_train)\n",
    "lstm_features = lstm_feature_model.predict(X_train)\n",
    "combined_features = np.hstack((cnn_features, lstm_features))\n",
    "\n",
    "# 使用 SVM 進行分類\n",
    "svm_classifier = SVC(kernel='linear', probability=True)\n",
    "svm_classifier.fit(combined_features, np.argmax(y_train, axis=1))\n",
    "\n",
    "# 評估\n",
    "cnn_test_features = cnn_feature_model.predict(X_test)\n",
    "lstm_test_features = lstm_feature_model.predict(X_test)\n",
    "combined_test_features = np.hstack((cnn_test_features, lstm_test_features))\n",
    "y_pred = svm_classifier.predict(combined_test_features)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "301/301 [==============================] - 6s 12ms/step - loss: 0.9663 - accuracy: 0.5062 - val_loss: 0.8829 - val_accuracy: 0.5794\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 3s 11ms/step - loss: 0.8741 - accuracy: 0.5808 - val_loss: 0.8531 - val_accuracy: 0.6118\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 3s 11ms/step - loss: 0.8156 - accuracy: 0.6225 - val_loss: 0.8092 - val_accuracy: 0.6359\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 3s 11ms/step - loss: 0.7869 - accuracy: 0.6383 - val_loss: 0.8057 - val_accuracy: 0.6309\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.7454 - accuracy: 0.6654 - val_loss: 0.8023 - val_accuracy: 0.6496\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.7008 - accuracy: 0.6896 - val_loss: 0.8030 - val_accuracy: 0.6355\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.6587 - accuracy: 0.7155 - val_loss: 0.8365 - val_accuracy: 0.6446\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.6093 - accuracy: 0.7374 - val_loss: 0.8496 - val_accuracy: 0.6459\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.5657 - accuracy: 0.7587 - val_loss: 0.8785 - val_accuracy: 0.6351\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.5113 - accuracy: 0.7863 - val_loss: 0.9447 - val_accuracy: 0.6284\n",
      "76/76 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.51      0.60       921\n",
      "           1       0.40      0.45      0.43       341\n",
      "           2       0.65      0.77      0.70      1144\n",
      "\n",
      "    accuracy                           0.63      2406\n",
      "   macro avg       0.59      0.58      0.58      2406\n",
      "weighted avg       0.64      0.63      0.63      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 單一 3 層 CNN 和 LSTM 網絡\n",
    "\n",
    "three_layer_cnn_lstm_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "three_layer_cnn_lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "three_layer_cnn_lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = three_layer_cnn_lstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "301/301 [==============================] - 8s 20ms/step - loss: 0.9308 - accuracy: 0.5315 - val_loss: 0.8537 - val_accuracy: 0.6014\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 6s 19ms/step - loss: 0.8474 - accuracy: 0.5983 - val_loss: 0.8252 - val_accuracy: 0.6018\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 6s 19ms/step - loss: 0.7812 - accuracy: 0.6455 - val_loss: 0.7756 - val_accuracy: 0.6554\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 6s 19ms/step - loss: 0.7399 - accuracy: 0.6758 - val_loss: 0.7595 - val_accuracy: 0.6600\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 6s 19ms/step - loss: 0.7054 - accuracy: 0.6918 - val_loss: 0.7767 - val_accuracy: 0.6571\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 6s 19ms/step - loss: 0.6703 - accuracy: 0.7138 - val_loss: 0.7686 - val_accuracy: 0.6621\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 5s 18ms/step - loss: 0.6361 - accuracy: 0.7288 - val_loss: 0.8316 - val_accuracy: 0.6484\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 5s 18ms/step - loss: 0.5984 - accuracy: 0.7501 - val_loss: 0.7979 - val_accuracy: 0.6563\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 6s 18ms/step - loss: 0.5635 - accuracy: 0.7627 - val_loss: 0.7962 - val_accuracy: 0.6426\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 5s 18ms/step - loss: 0.5208 - accuracy: 0.7873 - val_loss: 0.8436 - val_accuracy: 0.6588\n",
      "76/76 [==============================] - 1s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.66       921\n",
      "           1       0.48      0.43      0.45       341\n",
      "           2       0.67      0.76      0.71      1144\n",
      "\n",
      "    accuracy                           0.66      2406\n",
      "   macro avg       0.62      0.60      0.61      2406\n",
      "weighted avg       0.66      0.66      0.66      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 多重 CNN 和 LSTM 網絡\n",
    "\n",
    "multi_cnn_lstm_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "multi_cnn_lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "multi_cnn_lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = multi_cnn_lstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "301/301 [==============================] - 10s 19ms/step - loss: 0.9448 - accuracy: 0.5185 - val_loss: 0.8958 - val_accuracy: 0.5752\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 5s 16ms/step - loss: 0.8457 - accuracy: 0.5960 - val_loss: 0.8213 - val_accuracy: 0.6222\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 5s 18ms/step - loss: 0.7891 - accuracy: 0.6318 - val_loss: 0.8068 - val_accuracy: 0.6301\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 6s 19ms/step - loss: 0.7522 - accuracy: 0.6595 - val_loss: 0.7888 - val_accuracy: 0.6409\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 6s 19ms/step - loss: 0.7144 - accuracy: 0.6865 - val_loss: 0.8506 - val_accuracy: 0.6122\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 6s 18ms/step - loss: 0.6773 - accuracy: 0.7090 - val_loss: 0.7962 - val_accuracy: 0.6517\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 6s 18ms/step - loss: 0.6232 - accuracy: 0.7374 - val_loss: 0.8366 - val_accuracy: 0.6542\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 5s 18ms/step - loss: 0.5644 - accuracy: 0.7604 - val_loss: 0.8751 - val_accuracy: 0.6359\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 5s 18ms/step - loss: 0.5144 - accuracy: 0.7859 - val_loss: 0.9215 - val_accuracy: 0.6446\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 5s 18ms/step - loss: 0.4519 - accuracy: 0.8157 - val_loss: 0.9725 - val_accuracy: 0.6455\n",
      "76/76 [==============================] - 1s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68       921\n",
      "           1       0.43      0.42      0.42       341\n",
      "           2       0.71      0.66      0.68      1144\n",
      "\n",
      "    accuracy                           0.65      2406\n",
      "   macro avg       0.60      0.60      0.60      2406\n",
      "weighted avg       0.65      0.65      0.64      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "\n",
    "# 單一 3 層 CNN 和雙向 LSTM 網絡\n",
    "\n",
    "three_layer_cnn_bilstm_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "three_layer_cnn_bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "three_layer_cnn_bilstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = three_layer_cnn_bilstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "301/301 [==============================] - 15s 37ms/step - loss: 0.9241 - accuracy: 0.5359 - val_loss: 0.8500 - val_accuracy: 0.5910\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 11s 36ms/step - loss: 0.8308 - accuracy: 0.6085 - val_loss: 0.7977 - val_accuracy: 0.6355\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 10s 34ms/step - loss: 0.7775 - accuracy: 0.6452 - val_loss: 0.7722 - val_accuracy: 0.6446\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 10s 34ms/step - loss: 0.7345 - accuracy: 0.6739 - val_loss: 0.7682 - val_accuracy: 0.6496\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 10s 34ms/step - loss: 0.7001 - accuracy: 0.6907 - val_loss: 0.7721 - val_accuracy: 0.6413\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 10s 33ms/step - loss: 0.6607 - accuracy: 0.7146 - val_loss: 0.7958 - val_accuracy: 0.6309\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 10s 33ms/step - loss: 0.6177 - accuracy: 0.7358 - val_loss: 0.8184 - val_accuracy: 0.6584\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 10s 34ms/step - loss: 0.5893 - accuracy: 0.7481 - val_loss: 0.8019 - val_accuracy: 0.6584\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 10s 33ms/step - loss: 0.5283 - accuracy: 0.7805 - val_loss: 0.8724 - val_accuracy: 0.6338\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 10s 33ms/step - loss: 0.4825 - accuracy: 0.8004 - val_loss: 0.8655 - val_accuracy: 0.6455\n",
      "76/76 [==============================] - 1s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       921\n",
      "           1       0.45      0.28      0.34       341\n",
      "           2       0.67      0.74      0.70      1144\n",
      "\n",
      "    accuracy                           0.65      2406\n",
      "   macro avg       0.59      0.56      0.57      2406\n",
      "weighted avg       0.63      0.65      0.64      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 多重 CNN 和雙向 LSTM 網絡\n",
    "\n",
    "multi_cnn_bilstm_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "multi_cnn_bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "multi_cnn_bilstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = multi_cnn_bilstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "113-DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
