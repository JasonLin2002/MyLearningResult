{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.data_utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Dense, Flatten, LSTM, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 選擇數據處理模式：'N-R' 或 'R'\n",
    "mode = 'N-R'  # 可以選擇 'N-R' 或 'R'\n",
    "\n",
    "# 載入與預處理數據\n",
    "def load_semeval_data(file_paths):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) == 3:\n",
    "                    data.append(parts[2])\n",
    "                    labels.append(parts[1])\n",
    "    return pd.DataFrame({'tweet': data, 'label': labels})\n",
    "\n",
    "file_paths = [\n",
    "    './dataset/train/twitter-2013train-A.txt',\n",
    "    './dataset/train/twitter-2015train-A.txt',\n",
    "    './dataset/train/twitter-2016train-A.txt',\n",
    "]\n",
    "\n",
    "dataset = load_semeval_data(file_paths)\n",
    "\n",
    "# 預處理推文文本\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"https?:\\/\\/\\S+\", \"\", tweet)\n",
    "    tweet = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", tweet)\n",
    "    return tweet\n",
    "\n",
    "dataset['tweet'] = dataset['tweet'].apply(preprocess_tweet)\n",
    "\n",
    "# Tokenization 和 Padding 設置\n",
    "MAX_NB_WORDS = 10000\n",
    "MAX_SEQUENCE_LENGTH = 40  # 用於 N-R 模式\n",
    "REGION_SIZE = 10  # 每個區域的長度，用於 R 模式\n",
    "NUM_REGIONS = 4  # 區域數量，用於 R 模式\n",
    "EMBEDDING_DIM = 25\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(dataset['tweet'].values)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# 根據模式選擇不同的數據處理方法\n",
    "if mode == 'N-R':\n",
    "    # Non-Regional 模式，直接將推文轉為固定長度序列\n",
    "    X = tokenizer.texts_to_sequences(dataset['tweet'].values)\n",
    "    X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    input_length = MAX_SEQUENCE_LENGTH  # 設置模型的 input_length\n",
    "elif mode == 'R':\n",
    "    # Regional 模式，將推文分成多個區域並填充至相同長度\n",
    "    X = tokenizer.texts_to_sequences(dataset['tweet'].values)\n",
    "    X_padded = []\n",
    "    for tweet in X:\n",
    "        tweet_regions = []\n",
    "        for i in range(NUM_REGIONS):\n",
    "            start = i * REGION_SIZE\n",
    "            end = start + REGION_SIZE\n",
    "            region = tweet[start:end]\n",
    "            if len(region) < REGION_SIZE:\n",
    "                region = region + [0] * (REGION_SIZE - len(region))\n",
    "            tweet_regions.extend(region)\n",
    "        X_padded.append(tweet_regions)\n",
    "    X = np.array(X_padded)\n",
    "    input_length = NUM_REGIONS * REGION_SIZE  # 設置模型的 input_length\n",
    "else:\n",
    "    raise ValueError(\"Invalid mode. Choose 'N-R' or 'R'.\")\n",
    "\n",
    "# 標籤處理\n",
    "label_mapping = {'positive': 0, 'negative': 1, 'neutral': 2}\n",
    "y = dataset['label'].map(label_mapping).values\n",
    "y = pd.get_dummies(y).values\n",
    "\n",
    "# 數據分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 載入 GloVe 詞嵌入\n",
    "embeddings_index = {}\n",
    "with open('./dataset/glove.twitter.27B.25d.txt', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# 定義嵌入層，用於後續模型\n",
    "embedding_layer = Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                            input_length=input_length, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "405/405 [==============================] - 2s 3ms/step - loss: 1.0066 - accuracy: 0.4761 - val_loss: 0.9570 - val_accuracy: 0.5082\n",
      "Epoch 2/10\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 0.9321 - accuracy: 0.5369 - val_loss: 0.9162 - val_accuracy: 0.5338\n",
      "Epoch 3/10\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 0.9009 - accuracy: 0.5555 - val_loss: 0.8992 - val_accuracy: 0.5391\n",
      "Epoch 4/10\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 0.8847 - accuracy: 0.5651 - val_loss: 0.9071 - val_accuracy: 0.5478\n",
      "Epoch 5/10\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 0.8729 - accuracy: 0.5729 - val_loss: 0.8992 - val_accuracy: 0.5564\n",
      "Epoch 6/10\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 0.8643 - accuracy: 0.5805 - val_loss: 0.8911 - val_accuracy: 0.5617\n",
      "Epoch 7/10\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 0.8560 - accuracy: 0.5829 - val_loss: 0.8884 - val_accuracy: 0.5604\n",
      "Epoch 8/10\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 0.8505 - accuracy: 0.5877 - val_loss: 0.8916 - val_accuracy: 0.5570\n",
      "Epoch 9/10\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 0.8459 - accuracy: 0.5886 - val_loss: 0.8843 - val_accuracy: 0.5691\n",
      "Epoch 10/10\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 0.8392 - accuracy: 0.5926 - val_loss: 0.8854 - val_accuracy: 0.5669\n",
      "102/102 [==============================] - 0s 859us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59      1372\n",
      "           1       0.46      0.28      0.35       466\n",
      "           2       0.55      0.65      0.60      1397\n",
      "\n",
      "    accuracy                           0.57      3235\n",
      "   macro avg       0.54      0.50      0.51      3235\n",
      "weighted avg       0.56      0.57      0.56      3235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten\n",
    "\n",
    "# 建立單一 CNN 模型並加入 Flatten 層\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                        input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "cnn_model.add(Conv1D(filters=12, kernel_size=3, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=3))\n",
    "cnn_model.add(Flatten())  # 加入 Flatten 層\n",
    "cnn_model.add(Dense(3, activation='softmax'))\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = cnn_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "405/405 [==============================] - 25s 56ms/step - loss: 0.9247 - accuracy: 0.5328 - val_loss: 0.8803 - val_accuracy: 0.5654\n",
      "Epoch 2/10\n",
      "405/405 [==============================] - 22s 55ms/step - loss: 0.8870 - accuracy: 0.5627 - val_loss: 0.8698 - val_accuracy: 0.5731\n",
      "Epoch 3/10\n",
      "405/405 [==============================] - 22s 53ms/step - loss: 0.8755 - accuracy: 0.5666 - val_loss: 0.8447 - val_accuracy: 0.5904\n",
      "Epoch 4/10\n",
      "405/405 [==============================] - 21s 53ms/step - loss: 0.8601 - accuracy: 0.5788 - val_loss: 0.8433 - val_accuracy: 0.5904\n",
      "Epoch 5/10\n",
      "405/405 [==============================] - 21s 53ms/step - loss: 0.8495 - accuracy: 0.5871 - val_loss: 0.8389 - val_accuracy: 0.5932\n",
      "Epoch 6/10\n",
      "405/405 [==============================] - 22s 55ms/step - loss: 0.8388 - accuracy: 0.5973 - val_loss: 0.8314 - val_accuracy: 0.6080\n",
      "Epoch 7/10\n",
      "405/405 [==============================] - 23s 56ms/step - loss: 0.8291 - accuracy: 0.5960 - val_loss: 0.8264 - val_accuracy: 0.5929\n",
      "Epoch 8/10\n",
      "405/405 [==============================] - 23s 57ms/step - loss: 0.8128 - accuracy: 0.6131 - val_loss: 0.8166 - val_accuracy: 0.6223\n",
      "Epoch 9/10\n",
      "405/405 [==============================] - 25s 61ms/step - loss: 0.8087 - accuracy: 0.6162 - val_loss: 0.8109 - val_accuracy: 0.6195\n",
      "Epoch 10/10\n",
      "405/405 [==============================] - 25s 61ms/step - loss: 0.7947 - accuracy: 0.6286 - val_loss: 0.8038 - val_accuracy: 0.6297\n",
      "102/102 [==============================] - 2s 15ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67      1372\n",
      "           1       0.51      0.36      0.42       466\n",
      "           2       0.61      0.70      0.65      1397\n",
      "\n",
      "    accuracy                           0.63      3235\n",
      "   macro avg       0.60      0.57      0.58      3235\n",
      "weighted avg       0.63      0.63      0.63      3235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 單一 LSTM 模型 (Single LSTM)\n",
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# 建立單一 LSTM 模型\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                         input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm_model.add(Dense(3, activation='softmax'))\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = lstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "405/405 [==============================] - 12s 23ms/step - loss: 0.9646 - accuracy: 0.5009 - val_loss: 0.9118 - val_accuracy: 0.5369\n",
      "Epoch 2/10\n",
      "405/405 [==============================] - 8s 21ms/step - loss: 0.9107 - accuracy: 0.5500 - val_loss: 0.8943 - val_accuracy: 0.5533\n",
      "Epoch 3/10\n",
      "405/405 [==============================] - 8s 21ms/step - loss: 0.8944 - accuracy: 0.5584 - val_loss: 0.8871 - val_accuracy: 0.5583\n",
      "Epoch 4/10\n",
      "405/405 [==============================] - 8s 21ms/step - loss: 0.8803 - accuracy: 0.5635 - val_loss: 0.8741 - val_accuracy: 0.5713\n",
      "Epoch 5/10\n",
      "405/405 [==============================] - 9s 21ms/step - loss: 0.8735 - accuracy: 0.5733 - val_loss: 0.8692 - val_accuracy: 0.5691\n",
      "Epoch 6/10\n",
      "405/405 [==============================] - 8s 21ms/step - loss: 0.8643 - accuracy: 0.5768 - val_loss: 0.8669 - val_accuracy: 0.5719\n",
      "Epoch 7/10\n",
      "405/405 [==============================] - 8s 21ms/step - loss: 0.8561 - accuracy: 0.5822 - val_loss: 0.8615 - val_accuracy: 0.5762\n",
      "Epoch 8/10\n",
      "405/405 [==============================] - 8s 20ms/step - loss: 0.8502 - accuracy: 0.5880 - val_loss: 0.8655 - val_accuracy: 0.5750\n",
      "Epoch 9/10\n",
      "405/405 [==============================] - 8s 20ms/step - loss: 0.8489 - accuracy: 0.5933 - val_loss: 0.8584 - val_accuracy: 0.5713\n",
      "Epoch 10/10\n",
      "405/405 [==============================] - 8s 20ms/step - loss: 0.8419 - accuracy: 0.5948 - val_loss: 0.8570 - val_accuracy: 0.5762\n",
      "102/102 [==============================] - 1s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62      1372\n",
      "           1       0.48      0.15      0.23       466\n",
      "           2       0.56      0.66      0.61      1397\n",
      "\n",
      "    accuracy                           0.58      3235\n",
      "   macro avg       0.55      0.48      0.49      3235\n",
      "weighted avg       0.57      0.58      0.56      3235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CNN + LSTM 組合模型 (CNN + LSTM Combined Network)\n",
    "\n",
    "# 建立 CNN + LSTM 模型\n",
    "cnn_lstm_model = Sequential()\n",
    "cnn_lstm_model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                             input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "cnn_lstm_model.add(Conv1D(filters=12, kernel_size=3, activation='relu'))\n",
    "cnn_lstm_model.add(MaxPooling1D(pool_size=3))\n",
    "cnn_lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "cnn_lstm_model.add(Dense(3, activation='softmax'))\n",
    "cnn_lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "cnn_lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = cnn_lstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405/405 [==============================] - 0s 741us/step\n",
      "405/405 [==============================] - 5s 13ms/step\n",
      "102/102 [==============================] - 0s 738us/step\n",
      "102/102 [==============================] - 1s 12ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.65      0.60      1372\n",
      "           1       1.00      0.00      0.00       466\n",
      "           2       0.54      0.62      0.58      1397\n",
      "\n",
      "    accuracy                           0.55      3235\n",
      "   macro avg       0.70      0.43      0.39      3235\n",
      "weighted avg       0.61      0.55      0.50      3235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# CNN 特徵提取模型\n",
    "cnn_feature_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    Conv1D(filters=12, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    Flatten()\n",
    "])\n",
    "\n",
    "# LSTM 特徵提取模型\n",
    "lstm_feature_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Flatten()\n",
    "])\n",
    "\n",
    "# 提取 CNN 和 LSTM 特徵\n",
    "cnn_features = cnn_feature_model.predict(X_train)\n",
    "lstm_features = lstm_feature_model.predict(X_train)\n",
    "combined_features = np.hstack((cnn_features, lstm_features))\n",
    "\n",
    "# 使用 SVM 進行分類\n",
    "svm_classifier = SVC(kernel='linear', probability=True)\n",
    "svm_classifier.fit(combined_features, np.argmax(y_train, axis=1))\n",
    "\n",
    "# 評估\n",
    "cnn_test_features = cnn_feature_model.predict(X_test)\n",
    "lstm_test_features = lstm_feature_model.predict(X_test)\n",
    "combined_test_features = np.hstack((cnn_test_features, lstm_test_features))\n",
    "y_pred = svm_classifier.predict(combined_test_features)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "405/405 [==============================] - 6s 10ms/step - loss: 0.9541 - accuracy: 0.5107 - val_loss: 0.9096 - val_accuracy: 0.5363\n",
      "Epoch 2/10\n",
      "405/405 [==============================] - 4s 10ms/step - loss: 0.8961 - accuracy: 0.5531 - val_loss: 0.8834 - val_accuracy: 0.5586\n",
      "Epoch 3/10\n",
      "405/405 [==============================] - 4s 10ms/step - loss: 0.8630 - accuracy: 0.5836 - val_loss: 0.8754 - val_accuracy: 0.5604\n",
      "Epoch 4/10\n",
      "405/405 [==============================] - 4s 10ms/step - loss: 0.8378 - accuracy: 0.6022 - val_loss: 0.8803 - val_accuracy: 0.5638\n",
      "Epoch 5/10\n",
      "405/405 [==============================] - 4s 10ms/step - loss: 0.8061 - accuracy: 0.6177 - val_loss: 0.8645 - val_accuracy: 0.5651\n",
      "Epoch 6/10\n",
      "405/405 [==============================] - 4s 10ms/step - loss: 0.7691 - accuracy: 0.6398 - val_loss: 0.8768 - val_accuracy: 0.5728\n",
      "Epoch 7/10\n",
      "405/405 [==============================] - 4s 10ms/step - loss: 0.7318 - accuracy: 0.6623 - val_loss: 0.9045 - val_accuracy: 0.5731\n",
      "Epoch 8/10\n",
      "405/405 [==============================] - 4s 10ms/step - loss: 0.6940 - accuracy: 0.6819 - val_loss: 0.9658 - val_accuracy: 0.5725\n",
      "Epoch 9/10\n",
      "405/405 [==============================] - 4s 10ms/step - loss: 0.6349 - accuracy: 0.7154 - val_loss: 0.9574 - val_accuracy: 0.5623\n",
      "Epoch 10/10\n",
      "405/405 [==============================] - 4s 9ms/step - loss: 0.5860 - accuracy: 0.7458 - val_loss: 1.0288 - val_accuracy: 0.5478\n",
      "102/102 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.63      0.61      1372\n",
      "           1       0.35      0.23      0.27       466\n",
      "           2       0.55      0.57      0.56      1397\n",
      "\n",
      "    accuracy                           0.55      3235\n",
      "   macro avg       0.50      0.48      0.48      3235\n",
      "weighted avg       0.54      0.55      0.54      3235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 單一 3 層 CNN 和 LSTM 網絡\n",
    "\n",
    "three_layer_cnn_lstm_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "three_layer_cnn_lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "three_layer_cnn_lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = three_layer_cnn_lstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "405/405 [==============================] - 9s 18ms/step - loss: 0.9534 - accuracy: 0.5128 - val_loss: 0.8931 - val_accuracy: 0.5558\n",
      "Epoch 2/10\n",
      "405/405 [==============================] - 7s 17ms/step - loss: 0.8892 - accuracy: 0.5556 - val_loss: 0.8737 - val_accuracy: 0.5641\n",
      "Epoch 3/10\n",
      "405/405 [==============================] - 7s 17ms/step - loss: 0.8608 - accuracy: 0.5815 - val_loss: 0.8614 - val_accuracy: 0.5793\n",
      "Epoch 4/10\n",
      "405/405 [==============================] - 7s 17ms/step - loss: 0.8356 - accuracy: 0.5985 - val_loss: 0.9396 - val_accuracy: 0.5249\n",
      "Epoch 5/10\n",
      "405/405 [==============================] - 8s 19ms/step - loss: 0.8109 - accuracy: 0.6116 - val_loss: 0.8546 - val_accuracy: 0.5901\n",
      "Epoch 6/10\n",
      "405/405 [==============================] - 7s 17ms/step - loss: 0.7742 - accuracy: 0.6354 - val_loss: 0.8678 - val_accuracy: 0.5886\n",
      "Epoch 7/10\n",
      "405/405 [==============================] - 7s 17ms/step - loss: 0.7434 - accuracy: 0.6561 - val_loss: 0.8686 - val_accuracy: 0.5867\n",
      "Epoch 8/10\n",
      "405/405 [==============================] - 7s 17ms/step - loss: 0.7131 - accuracy: 0.6717 - val_loss: 0.9063 - val_accuracy: 0.5598\n",
      "Epoch 9/10\n",
      "405/405 [==============================] - 7s 17ms/step - loss: 0.6772 - accuracy: 0.6946 - val_loss: 0.9212 - val_accuracy: 0.5932\n",
      "Epoch 10/10\n",
      "405/405 [==============================] - 7s 17ms/step - loss: 0.6355 - accuracy: 0.7149 - val_loss: 0.9233 - val_accuracy: 0.5917\n",
      "102/102 [==============================] - 1s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.60      0.62      1372\n",
      "           1       0.49      0.31      0.38       466\n",
      "           2       0.57      0.67      0.62      1397\n",
      "\n",
      "    accuracy                           0.59      3235\n",
      "   macro avg       0.57      0.53      0.54      3235\n",
      "weighted avg       0.59      0.59      0.59      3235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 多重 CNN 和 LSTM 網絡\n",
    "\n",
    "multi_cnn_lstm_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "multi_cnn_lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "multi_cnn_lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = multi_cnn_lstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "405/405 [==============================] - 11s 17ms/step - loss: 0.9557 - accuracy: 0.5097 - val_loss: 0.9154 - val_accuracy: 0.5376\n",
      "Epoch 2/10\n",
      "405/405 [==============================] - 6s 15ms/step - loss: 0.8946 - accuracy: 0.5582 - val_loss: 0.8858 - val_accuracy: 0.5660\n",
      "Epoch 3/10\n",
      "405/405 [==============================] - 6s 15ms/step - loss: 0.8637 - accuracy: 0.5815 - val_loss: 0.8708 - val_accuracy: 0.5759\n",
      "Epoch 4/10\n",
      "405/405 [==============================] - 6s 15ms/step - loss: 0.8342 - accuracy: 0.5962 - val_loss: 0.8624 - val_accuracy: 0.5849\n",
      "Epoch 5/10\n",
      "405/405 [==============================] - 6s 16ms/step - loss: 0.8057 - accuracy: 0.6151 - val_loss: 0.8729 - val_accuracy: 0.5743\n",
      "Epoch 6/10\n",
      "405/405 [==============================] - 7s 16ms/step - loss: 0.7657 - accuracy: 0.6390 - val_loss: 0.8727 - val_accuracy: 0.5734\n",
      "Epoch 7/10\n",
      "405/405 [==============================] - 7s 17ms/step - loss: 0.7217 - accuracy: 0.6654 - val_loss: 0.9257 - val_accuracy: 0.5666\n",
      "Epoch 8/10\n",
      "405/405 [==============================] - 7s 18ms/step - loss: 0.6700 - accuracy: 0.6961 - val_loss: 0.9577 - val_accuracy: 0.5663\n",
      "Epoch 9/10\n",
      "405/405 [==============================] - 44s 108ms/step - loss: 0.6135 - accuracy: 0.7281 - val_loss: 1.0116 - val_accuracy: 0.5431\n",
      "Epoch 10/10\n",
      "405/405 [==============================] - 29s 71ms/step - loss: 0.5649 - accuracy: 0.7531 - val_loss: 1.0038 - val_accuracy: 0.5589\n",
      "102/102 [==============================] - 1s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.60      1372\n",
      "           1       0.41      0.39      0.40       466\n",
      "           2       0.57      0.58      0.57      1397\n",
      "\n",
      "    accuracy                           0.56      3235\n",
      "   macro avg       0.52      0.52      0.52      3235\n",
      "weighted avg       0.56      0.56      0.56      3235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "\n",
    "# 單一 3 層 CNN 和雙向 LSTM 網絡\n",
    "\n",
    "three_layer_cnn_bilstm_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "three_layer_cnn_bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "three_layer_cnn_bilstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = three_layer_cnn_bilstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "405/405 [==============================] - 18s 33ms/step - loss: 0.9489 - accuracy: 0.5090 - val_loss: 0.8947 - val_accuracy: 0.5474\n",
      "Epoch 2/10\n",
      "405/405 [==============================] - 13s 32ms/step - loss: 0.8897 - accuracy: 0.5668 - val_loss: 0.8779 - val_accuracy: 0.5663\n",
      "Epoch 3/10\n",
      "405/405 [==============================] - 14s 34ms/step - loss: 0.8603 - accuracy: 0.5818 - val_loss: 0.8618 - val_accuracy: 0.5731\n",
      "Epoch 4/10\n",
      "405/405 [==============================] - 12s 31ms/step - loss: 0.8278 - accuracy: 0.6060 - val_loss: 0.8543 - val_accuracy: 0.5740\n",
      "Epoch 5/10\n",
      "405/405 [==============================] - 13s 31ms/step - loss: 0.7993 - accuracy: 0.6199 - val_loss: 0.8471 - val_accuracy: 0.5889\n",
      "Epoch 6/10\n",
      "405/405 [==============================] - 13s 32ms/step - loss: 0.7652 - accuracy: 0.6397 - val_loss: 0.8504 - val_accuracy: 0.5910\n",
      "Epoch 7/10\n",
      "405/405 [==============================] - 13s 32ms/step - loss: 0.7269 - accuracy: 0.6664 - val_loss: 0.8666 - val_accuracy: 0.5883\n",
      "Epoch 8/10\n",
      "405/405 [==============================] - 13s 32ms/step - loss: 0.6900 - accuracy: 0.6894 - val_loss: 0.8964 - val_accuracy: 0.5910\n",
      "Epoch 9/10\n",
      "405/405 [==============================] - 13s 33ms/step - loss: 0.6457 - accuracy: 0.7135 - val_loss: 0.9169 - val_accuracy: 0.5771\n",
      "Epoch 10/10\n",
      "405/405 [==============================] - 13s 33ms/step - loss: 0.6063 - accuracy: 0.7342 - val_loss: 0.9609 - val_accuracy: 0.5951\n",
      "102/102 [==============================] - 1s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.63      1372\n",
      "           1       0.47      0.24      0.31       466\n",
      "           2       0.58      0.68      0.62      1397\n",
      "\n",
      "    accuracy                           0.60      3235\n",
      "   macro avg       0.56      0.52      0.52      3235\n",
      "weighted avg       0.59      0.60      0.58      3235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 多重 CNN 和雙向 LSTM 網絡\n",
    "\n",
    "multi_cnn_bilstm_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "multi_cnn_bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "multi_cnn_bilstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = multi_cnn_bilstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "113-DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
