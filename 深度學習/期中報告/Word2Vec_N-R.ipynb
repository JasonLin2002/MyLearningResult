{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.data_utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Dense, Flatten, LSTM, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 選擇數據處理模式：'N-R' 或 'R'\n",
    "mode = 'R'  # 可以選擇 'N-R' 或 'R'\n",
    "\n",
    "# 載入與預處理數據\n",
    "def load_semeval_data(file_paths):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) == 3:\n",
    "                    data.append(parts[2])\n",
    "                    labels.append(parts[1])\n",
    "    return pd.DataFrame({'tweet': data, 'label': labels})\n",
    "\n",
    "file_paths = [\n",
    "    './dataset/train/twitter-2013train-A.txt',\n",
    "    './dataset/train/twitter-2014test-A.txt',\n",
    "    './dataset/train/twitter-2015train-A.txt'\n",
    "]\n",
    "\n",
    "dataset = load_semeval_data(file_paths)\n",
    "\n",
    "# 預處理推文文本\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"https?:\\/\\/\\S+\", \"\", tweet)\n",
    "    tweet = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", tweet)\n",
    "    return tweet\n",
    "\n",
    "dataset['tweet'] = dataset['tweet'].apply(preprocess_tweet)\n",
    "\n",
    "# Tokenization 和 Padding 設置\n",
    "MAX_NB_WORDS = 10000\n",
    "MAX_SEQUENCE_LENGTH = 40  # 用於 N-R 模式\n",
    "REGION_SIZE = 10  # 每個區域的長度，用於 R 模式\n",
    "NUM_REGIONS = 4  # 區域數量，用於 R 模式\n",
    "EMBEDDING_DIM = 25\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(dataset['tweet'].values)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# 根據模式選擇不同的數據處理方法\n",
    "if mode == 'N-R':\n",
    "    # Non-Regional 模式，直接將推文轉為固定長度序列\n",
    "    X = tokenizer.texts_to_sequences(dataset['tweet'].values)\n",
    "    X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    input_length = MAX_SEQUENCE_LENGTH  # 設置模型的 input_length\n",
    "elif mode == 'R':\n",
    "    # Regional 模式，將推文分成多個區域並填充至相同長度\n",
    "    X = tokenizer.texts_to_sequences(dataset['tweet'].values)\n",
    "    X_padded = []\n",
    "    for tweet in X:\n",
    "        tweet_regions = []\n",
    "        for i in range(NUM_REGIONS):\n",
    "            start = i * REGION_SIZE\n",
    "            end = start + REGION_SIZE\n",
    "            region = tweet[start:end]\n",
    "            if len(region) < REGION_SIZE:\n",
    "                region = region + [0] * (REGION_SIZE - len(region))\n",
    "            tweet_regions.extend(region)\n",
    "        X_padded.append(tweet_regions)\n",
    "    X = np.array(X_padded)\n",
    "    input_length = NUM_REGIONS * REGION_SIZE  # 設置模型的 input_length\n",
    "else:\n",
    "    raise ValueError(\"Invalid mode. Choose 'N-R' or 'R'.\")\n",
    "\n",
    "# 標籤處理\n",
    "label_mapping = {'positive': 0, 'negative': 1, 'neutral': 2}\n",
    "y = dataset['label'].map(label_mapping).values\n",
    "y = pd.get_dummies(y).values\n",
    "\n",
    "# 數據分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 訓練 Word2Vec 模型\n",
    "tokenized_sentences = [tweet.split() for tweet in dataset['tweet'].values]\n",
    "word2vec_model = Word2Vec(sentences=tokenized_sentences,\n",
    "                          vector_size=EMBEDDING_DIM,  # 詞向量維度為 25\n",
    "                          window=5,                   # 最大跳躍距離設為 5\n",
    "                          min_count=5,                # 最低頻次為 5\n",
    "                          sg=0,                       # CBOW 模型 (sg=0)\n",
    "                          workers=4)                  # 使用 4 個核心進行訓練\n",
    "\n",
    "# 將詞向量進行標準化\n",
    "def normalize_vector(vector):\n",
    "    v_min, v_max = np.min(vector), np.max(vector)\n",
    "    return (vector - v_min) / (v_max - v_min) if v_max > v_min else vector\n",
    "\n",
    "# 構建嵌入矩陣\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        embedding_vector = word2vec_model.wv[word]\n",
    "        embedding_matrix[i] = normalize_vector(embedding_vector)\n",
    "\n",
    "# 定義嵌入層，用於後續模型\n",
    "embedding_layer = Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                            input_length=input_length, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "301/301 [==============================] - 1s 3ms/step - loss: 1.0044 - accuracy: 0.4588 - val_loss: 0.9776 - val_accuracy: 0.5037\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 1s 2ms/step - loss: 0.9811 - accuracy: 0.4878 - val_loss: 0.9688 - val_accuracy: 0.5046\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 1s 2ms/step - loss: 0.9721 - accuracy: 0.5012 - val_loss: 0.9703 - val_accuracy: 0.4888\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 1s 2ms/step - loss: 0.9677 - accuracy: 0.5045 - val_loss: 0.9684 - val_accuracy: 0.5237\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 1s 3ms/step - loss: 0.9653 - accuracy: 0.5061 - val_loss: 0.9663 - val_accuracy: 0.5179\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 1s 2ms/step - loss: 0.9637 - accuracy: 0.5050 - val_loss: 0.9663 - val_accuracy: 0.5175\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 1s 2ms/step - loss: 0.9609 - accuracy: 0.5062 - val_loss: 0.9613 - val_accuracy: 0.5212\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 1s 2ms/step - loss: 0.9586 - accuracy: 0.5070 - val_loss: 0.9576 - val_accuracy: 0.4996\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 1s 2ms/step - loss: 0.9560 - accuracy: 0.5102 - val_loss: 0.9554 - val_accuracy: 0.5062\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 1s 3ms/step - loss: 0.9556 - accuracy: 0.5137 - val_loss: 0.9539 - val_accuracy: 0.5233\n",
      "76/76 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.44      0.45       921\n",
      "           1       0.62      0.01      0.03       341\n",
      "           2       0.56      0.74      0.64      1144\n",
      "\n",
      "    accuracy                           0.52      2406\n",
      "   macro avg       0.55      0.40      0.37      2406\n",
      "weighted avg       0.53      0.52      0.48      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten\n",
    "\n",
    "# 建立單一 CNN 模型並加入 Flatten 層\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                        input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "cnn_model.add(Conv1D(filters=12, kernel_size=3, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=3))\n",
    "cnn_model.add(Flatten())  # 加入 Flatten 層\n",
    "cnn_model.add(Dense(3, activation='softmax'))\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = cnn_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "301/301 [==============================] - 28s 86ms/step - loss: 1.0090 - accuracy: 0.4497 - val_loss: 0.9936 - val_accuracy: 0.4759\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 25s 84ms/step - loss: 0.9946 - accuracy: 0.4692 - val_loss: 1.0034 - val_accuracy: 0.3828\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 25s 82ms/step - loss: 0.9839 - accuracy: 0.4851 - val_loss: 0.9749 - val_accuracy: 0.5017\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 24s 80ms/step - loss: 0.9774 - accuracy: 0.4880 - val_loss: 0.9769 - val_accuracy: 0.4850\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 25s 83ms/step - loss: 0.9782 - accuracy: 0.4940 - val_loss: 0.9678 - val_accuracy: 0.4950\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 25s 84ms/step - loss: 0.9740 - accuracy: 0.4953 - val_loss: 0.9708 - val_accuracy: 0.5091\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 26s 87ms/step - loss: 0.9765 - accuracy: 0.4897 - val_loss: 0.9592 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 25s 85ms/step - loss: 0.9731 - accuracy: 0.4940 - val_loss: 0.9630 - val_accuracy: 0.5025\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 25s 83ms/step - loss: 0.9713 - accuracy: 0.4941 - val_loss: 0.9647 - val_accuracy: 0.5087\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 25s 83ms/step - loss: 0.9723 - accuracy: 0.4922 - val_loss: 0.9598 - val_accuracy: 0.5091\n",
      "76/76 [==============================] - 2s 22ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.58      0.49       921\n",
      "           1       0.00      0.00      0.00       341\n",
      "           2       0.60      0.61      0.60      1144\n",
      "\n",
      "    accuracy                           0.51      2406\n",
      "   macro avg       0.34      0.39      0.36      2406\n",
      "weighted avg       0.45      0.51      0.47      2406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# 單一 LSTM 模型 (Single LSTM)\n",
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# 建立單一 LSTM 模型\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                         input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm_model.add(Dense(3, activation='softmax'))\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = lstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "301/301 [==============================] - 41s 123ms/step - loss: 1.0009 - accuracy: 0.4631 - val_loss: 0.9766 - val_accuracy: 0.4958\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 6s 21ms/step - loss: 0.9790 - accuracy: 0.4870 - val_loss: 0.9752 - val_accuracy: 0.4958\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 6s 20ms/step - loss: 0.9760 - accuracy: 0.4930 - val_loss: 0.9544 - val_accuracy: 0.5067\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 6s 20ms/step - loss: 0.9732 - accuracy: 0.4939 - val_loss: 0.9571 - val_accuracy: 0.5058\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 6s 20ms/step - loss: 0.9717 - accuracy: 0.5011 - val_loss: 0.9513 - val_accuracy: 0.5112\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 6s 20ms/step - loss: 0.9679 - accuracy: 0.5001 - val_loss: 0.9544 - val_accuracy: 0.5166\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 6s 20ms/step - loss: 0.9679 - accuracy: 0.4997 - val_loss: 0.9599 - val_accuracy: 0.5012\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 6s 21ms/step - loss: 0.9663 - accuracy: 0.5028 - val_loss: 0.9500 - val_accuracy: 0.5208\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 6s 21ms/step - loss: 0.9636 - accuracy: 0.5019 - val_loss: 0.9506 - val_accuracy: 0.5150\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 6s 21ms/step - loss: 0.9626 - accuracy: 0.5004 - val_loss: 0.9518 - val_accuracy: 0.5200\n",
      "76/76 [==============================] - 1s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.64      0.52       921\n",
      "           1       0.00      0.00      0.00       341\n",
      "           2       0.62      0.58      0.60      1144\n",
      "\n",
      "    accuracy                           0.52      2406\n",
      "   macro avg       0.35      0.41      0.37      2406\n",
      "weighted avg       0.46      0.52      0.48      2406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# CNN + LSTM 組合模型 (CNN + LSTM Combined Network)\n",
    "\n",
    "# 建立 CNN + LSTM 模型\n",
    "cnn_lstm_model = Sequential()\n",
    "cnn_lstm_model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                             input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "cnn_lstm_model.add(Conv1D(filters=12, kernel_size=3, activation='relu'))\n",
    "cnn_lstm_model.add(MaxPooling1D(pool_size=3))\n",
    "cnn_lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "cnn_lstm_model.add(Dense(3, activation='softmax'))\n",
    "cnn_lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "cnn_lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = cnn_lstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 799us/step\n",
      "301/301 [==============================] - 4s 13ms/step\n",
      "76/76 [==============================] - 0s 807us/step\n",
      "76/76 [==============================] - 1s 13ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.49      0.47       921\n",
      "           1       0.00      0.00      0.00       341\n",
      "           2       0.56      0.70      0.62      1144\n",
      "\n",
      "    accuracy                           0.52      2406\n",
      "   macro avg       0.34      0.39      0.36      2406\n",
      "weighted avg       0.44      0.52      0.47      2406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# CNN 特徵提取模型\n",
    "cnn_feature_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    Conv1D(filters=12, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    Flatten()\n",
    "])\n",
    "\n",
    "# LSTM 特徵提取模型\n",
    "lstm_feature_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Flatten()\n",
    "])\n",
    "\n",
    "# 提取 CNN 和 LSTM 特徵\n",
    "cnn_features = cnn_feature_model.predict(X_train)\n",
    "lstm_features = lstm_feature_model.predict(X_train)\n",
    "combined_features = np.hstack((cnn_features, lstm_features))\n",
    "\n",
    "# 使用 SVM 進行分類\n",
    "svm_classifier = SVC(kernel='linear', probability=True)\n",
    "svm_classifier.fit(combined_features, np.argmax(y_train, axis=1))\n",
    "\n",
    "# 評估\n",
    "cnn_test_features = cnn_feature_model.predict(X_test)\n",
    "lstm_test_features = lstm_feature_model.predict(X_test)\n",
    "combined_test_features = np.hstack((cnn_test_features, lstm_test_features))\n",
    "y_pred = svm_classifier.predict(combined_test_features)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "301/301 [==============================] - 6s 12ms/step - loss: 1.0006 - accuracy: 0.4611 - val_loss: 0.9677 - val_accuracy: 0.5104\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 3s 11ms/step - loss: 0.9817 - accuracy: 0.4857 - val_loss: 0.9743 - val_accuracy: 0.4896\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 3s 11ms/step - loss: 0.9729 - accuracy: 0.4931 - val_loss: 0.9582 - val_accuracy: 0.5116\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 3s 11ms/step - loss: 0.9639 - accuracy: 0.5025 - val_loss: 0.9685 - val_accuracy: 0.4979\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.9616 - accuracy: 0.5035 - val_loss: 0.9546 - val_accuracy: 0.5096\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.9574 - accuracy: 0.5031 - val_loss: 1.0042 - val_accuracy: 0.4609\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.9496 - accuracy: 0.5162 - val_loss: 0.9552 - val_accuracy: 0.5083\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.9448 - accuracy: 0.5200 - val_loss: 0.9627 - val_accuracy: 0.5062\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.9399 - accuracy: 0.5222 - val_loss: 0.9498 - val_accuracy: 0.5129\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 3s 10ms/step - loss: 0.9379 - accuracy: 0.5229 - val_loss: 0.9654 - val_accuracy: 0.5249\n",
      "76/76 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.54      0.49       921\n",
      "           1       0.50      0.00      0.01       341\n",
      "           2       0.58      0.67      0.62      1144\n",
      "\n",
      "    accuracy                           0.52      2406\n",
      "   macro avg       0.51      0.40      0.37      2406\n",
      "weighted avg       0.52      0.52      0.49      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 單一 3 層 CNN 和 LSTM 網絡\n",
    "\n",
    "three_layer_cnn_lstm_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "three_layer_cnn_lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "three_layer_cnn_lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = three_layer_cnn_lstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "301/301 [==============================] - 8s 20ms/step - loss: 0.9990 - accuracy: 0.4696 - val_loss: 0.9849 - val_accuracy: 0.4954\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 6s 18ms/step - loss: 0.9889 - accuracy: 0.4774 - val_loss: 0.9784 - val_accuracy: 0.5100\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 6s 19ms/step - loss: 0.9743 - accuracy: 0.4945 - val_loss: 0.9606 - val_accuracy: 0.4988\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 6s 18ms/step - loss: 0.9711 - accuracy: 0.5041 - val_loss: 0.9733 - val_accuracy: 0.5012\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 6s 18ms/step - loss: 0.9709 - accuracy: 0.5014 - val_loss: 0.9557 - val_accuracy: 0.5150\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 6s 19ms/step - loss: 0.9643 - accuracy: 0.5077 - val_loss: 0.9496 - val_accuracy: 0.5104\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 6s 18ms/step - loss: 0.9595 - accuracy: 0.5103 - val_loss: 0.9503 - val_accuracy: 0.5154\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 6s 18ms/step - loss: 0.9605 - accuracy: 0.5085 - val_loss: 0.9507 - val_accuracy: 0.5062\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 6s 18ms/step - loss: 0.9620 - accuracy: 0.5107 - val_loss: 0.9481 - val_accuracy: 0.5125\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 5s 18ms/step - loss: 0.9572 - accuracy: 0.5116 - val_loss: 0.9504 - val_accuracy: 0.5033\n",
      "76/76 [==============================] - 1s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.71      0.54       921\n",
      "           1       0.00      0.00      0.00       341\n",
      "           2       0.63      0.49      0.55      1144\n",
      "\n",
      "    accuracy                           0.50      2406\n",
      "   macro avg       0.35      0.40      0.36      2406\n",
      "weighted avg       0.46      0.50      0.47      2406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# 多重 CNN 和 LSTM 網絡\n",
    "\n",
    "multi_cnn_lstm_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "multi_cnn_lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "multi_cnn_lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = multi_cnn_lstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "301/301 [==============================] - 10s 18ms/step - loss: 0.9963 - accuracy: 0.4748 - val_loss: 0.9695 - val_accuracy: 0.4888\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 5s 17ms/step - loss: 0.9762 - accuracy: 0.4963 - val_loss: 0.9657 - val_accuracy: 0.5179\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 5s 17ms/step - loss: 0.9693 - accuracy: 0.5052 - val_loss: 0.9654 - val_accuracy: 0.5150\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 5s 17ms/step - loss: 0.9647 - accuracy: 0.5060 - val_loss: 0.9523 - val_accuracy: 0.5187\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 5s 17ms/step - loss: 0.9579 - accuracy: 0.5078 - val_loss: 0.9496 - val_accuracy: 0.5154\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 5s 17ms/step - loss: 0.9562 - accuracy: 0.5119 - val_loss: 0.9498 - val_accuracy: 0.5258\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 5s 17ms/step - loss: 0.9491 - accuracy: 0.5165 - val_loss: 0.9469 - val_accuracy: 0.5154\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 5s 17ms/step - loss: 0.9433 - accuracy: 0.5195 - val_loss: 0.9462 - val_accuracy: 0.5249\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 5s 17ms/step - loss: 0.9358 - accuracy: 0.5268 - val_loss: 0.9580 - val_accuracy: 0.5162\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 5s 18ms/step - loss: 0.9295 - accuracy: 0.5330 - val_loss: 0.9568 - val_accuracy: 0.5187\n",
      "76/76 [==============================] - 1s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.73      0.56       921\n",
      "           1       0.00      0.00      0.00       341\n",
      "           2       0.64      0.50      0.56      1144\n",
      "\n",
      "    accuracy                           0.52      2406\n",
      "   macro avg       0.36      0.41      0.37      2406\n",
      "weighted avg       0.47      0.52      0.48      2406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jk121\\.conda\\envs\\DL-113\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "\n",
    "# 單一 3 層 CNN 和雙向 LSTM 網絡\n",
    "\n",
    "three_layer_cnn_bilstm_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "three_layer_cnn_bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "three_layer_cnn_bilstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = three_layer_cnn_bilstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "301/301 [==============================] - 15s 35ms/step - loss: 1.0038 - accuracy: 0.4542 - val_loss: 0.9771 - val_accuracy: 0.4759\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 11s 35ms/step - loss: 0.9771 - accuracy: 0.4966 - val_loss: 0.9677 - val_accuracy: 0.5042\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 11s 35ms/step - loss: 0.9726 - accuracy: 0.4975 - val_loss: 0.9564 - val_accuracy: 0.5104\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 11s 37ms/step - loss: 0.9635 - accuracy: 0.5061 - val_loss: 0.9617 - val_accuracy: 0.5087\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 11s 35ms/step - loss: 0.9621 - accuracy: 0.5080 - val_loss: 0.9785 - val_accuracy: 0.4859\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 11s 35ms/step - loss: 0.9611 - accuracy: 0.5077 - val_loss: 0.9536 - val_accuracy: 0.5079\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 11s 36ms/step - loss: 0.9571 - accuracy: 0.5085 - val_loss: 0.9579 - val_accuracy: 0.5067\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 11s 36ms/step - loss: 0.9551 - accuracy: 0.5055 - val_loss: 0.9436 - val_accuracy: 0.5087\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 11s 36ms/step - loss: 0.9520 - accuracy: 0.5132 - val_loss: 0.9453 - val_accuracy: 0.5125\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 11s 36ms/step - loss: 0.9481 - accuracy: 0.5159 - val_loss: 0.9489 - val_accuracy: 0.5133\n",
      "76/76 [==============================] - 1s 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.48      0.46       921\n",
      "           1       0.67      0.01      0.01       341\n",
      "           2       0.57      0.69      0.62      1144\n",
      "\n",
      "    accuracy                           0.51      2406\n",
      "   macro avg       0.56      0.39      0.36      2406\n",
      "weighted avg       0.53      0.51      0.47      2406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 多重 CNN 和雙向 LSTM 網絡\n",
    "\n",
    "multi_cnn_bilstm_model = Sequential([\n",
    "    Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "multi_cnn_bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練與評估\n",
    "multi_cnn_bilstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = multi_cnn_bilstm_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "113-DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
